{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7082e319-ff60-46ac-9cd2-8448bc5888f3",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3db767-9f9b-4784-953f-7956c391dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import string\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from nltk import edit_distance as lev_dist\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b85d2-2b88-4d8b-9433-d30ee2a963bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set pandas viewing options\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6074a-895a-4439-adac-28f0ef68e899",
   "metadata": {},
   "source": [
    "# Outstanding Issues\n",
    "* The CUAD dataset doesn't have clear page boundaries in the ground truth text files\n",
    "* If there is a region of bad segmentation (multiple boxes have bad text), then it throws the alignment wrt gt boxes completely off. Succeeding gt segments all go unlabeled. Eg: DeltathreeInc_19991102_S-1A_EX-10.19_6227850_EX-10.19_Co-Branding Agreement_ Service Agreement Window Size: 2\n",
    "    * need to find a way to advance window of gts we're looking at\n",
    "* More bbox preds than number of gt segments. Should every bbox be assigned to some gt? Or should every gt be assigned a bbox?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6bc09-969c-4aee-9198-3d32a73ada3b",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099e7b1-3d6c-4319-a757-d664e7005aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gt_file(fname, split_patt='\\n ', debug=False):\n",
    "    '''Reads the GT .txt files from CUAD dataset'''\n",
    "    if debug:\n",
    "        print(f'fname: {fname}')\n",
    "    \n",
    "    with open(fname, 'r') as fh:\n",
    "        lines = fh.read()\n",
    "    \n",
    "    # split text by split pattern\n",
    "    split_lines = lines.split(split_patt)\n",
    "    split_lines_df = pd.DataFrame({'text_segment': split_lines})\n",
    "    \n",
    "    # create cols and clean text\n",
    "    split_lines_df['assigned_bbox'] = None\n",
    "    split_lines_df['assigned_page'] = None\n",
    "    split_lines_df['text_segment'] = split_lines_df['text_segment'].str.strip()\n",
    "    \n",
    "    return split_lines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b0d203-7aac-4d83-bce4-b059ac126d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_pred_bbox(pred_row, unassigned_gt_fc, percent_match=0.5, remove_punc=True, lowercase=True):\n",
    "    '''Matches Pred Text Segment with GT Text Segment'''\n",
    "    #TODO: add remove_punc and lowercase as user args\n",
    "    pred_seg = pred_row.loc['text']\n",
    "    \n",
    "    if remove_punc:\n",
    "        pred_seg = ''.join(char for char in pred_seg if char.isalnum())\n",
    "        unassigned_gt_fc['text_segment'] = unassigned_gt_fc['text_segment'].apply(lambda gt_text: ''.join(char for char in gt_text if char.isalnum()))\n",
    "    \n",
    "    if lowercase:\n",
    "        pred_seg = pred_seg.lower()\n",
    "        unassigned_gt_fc['text_segment'] = unassigned_gt_fc['text_segment'].str.lower()\n",
    "    \n",
    "    # compute edit distances for 'window_size' num of unassigned text segments \n",
    "    unassigned_gt_fc['edit_distances'] = unassigned_gt_fc['text_segment'].apply(lambda gt_text: lev_dist(gt_text, pred_seg))\n",
    "    \n",
    "    # if the edit distance is greater than some percent of the predicted text then ignore the bbox\n",
    "    if unassigned_gt_fc['edit_distances'].min() >= int(percent_match * len(pred_seg)):\n",
    "        match_idx = None\n",
    "        coords = None\n",
    "        page = None\n",
    "    \n",
    "    else:\n",
    "        match_idx = unassigned_gt_fc['edit_distances'].idxmin()\n",
    "\n",
    "        coords = {}\n",
    "        coords['xmin'] = pred_row.loc['xmin']\n",
    "        coords['ymin'] = pred_row.loc['ymin']\n",
    "        coords['xmax'] = pred_row.loc['xmax']\n",
    "        coords['ymax'] = pred_row.loc['ymax']\n",
    "        \n",
    "        coords = json.dumps(coords)\n",
    "        \n",
    "        page = pred_row.loc['page']\n",
    "    \n",
    "    return match_idx, coords, page, unassigned_gt_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2830ab-1570-4262-95d7-e46751e80a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Can this workflow be optimized? Avoid looping through df using df.iterrows()\n",
    "def process_doc(doc_id, pred_file_contents, gt_file_contents, \n",
    "                window_size=2, debug=False, percent_match=0.5,\n",
    "                remove_punc=True, lowercase=True):\n",
    "    '''Defines Execution Flow for a Single Doc\n",
    "    '''\n",
    "    \n",
    "    # keep track of which bboxes have been updated\n",
    "    updated_bboxes = []\n",
    "    for row_idx, pred_row in tqdm(pred_file_contents.iterrows(), total=len(pred_file_contents), desc='Per Doc Prog Bar'):        \n",
    "        #TODO: Add debug statements to verify this logic\n",
    "        # get idx of last updated entry and fetch unassigned bboxes after that. \n",
    "        # If a box was missed earlier and \n",
    "        # succeeding segments were assigned bboxes, then ignore that            \n",
    "        not_null_cond = gt_file_contents['assigned_bbox'].notnull()\n",
    "        not_null_gt_file_contents = gt_file_contents.loc[not_null_cond]\n",
    "        \n",
    "        if not_null_gt_file_contents.empty:\n",
    "            last_assigned_gt_idx = 0\n",
    "        else:\n",
    "            last_assigned_gt_idx = not_null_gt_file_contents.index.max()\n",
    "        \n",
    "        # index only those gt text segments that do not have any succeeding entries that have been assigned \n",
    "        candidate_gt_file_contents = gt_file_contents.loc[last_assigned_gt_idx: ]\n",
    "        \n",
    "        # define cond to fetch just those gt_segments that haven't been assigned yet    \n",
    "        unassigned_gt_cond = candidate_gt_file_contents['assigned_bbox'].isnull()\n",
    "        unassigned_gt_fc = candidate_gt_file_contents.loc[unassigned_gt_cond]\n",
    "        \n",
    "        \n",
    "        # if no gt_segments are remaining then break\n",
    "        if unassigned_gt_fc.empty:\n",
    "            print(\"ALL GT BOXES HAVE BEEN ASSIGNED. EXITING LOOP\")            \n",
    "\n",
    "            if debug:\n",
    "                print(f\"Is Candidate GT File Contents Empty: {candidate_gt_file_contents.empty}\")\n",
    "                print(f\"Is Unassigned Candidate GT File Contents Empty: {unassigned_gt_fc.empty}\")\n",
    "            \n",
    "            break\n",
    "            \n",
    "        # fetch window_size number of gt_text_segments\n",
    "        unassigned_gt_fc = unassigned_gt_fc.iloc[:window_size]\n",
    "        \n",
    "        # get results from matching\n",
    "        match_idx, coords, page_num, updated_gt_fc = match_pred_bbox(pred_row, unassigned_gt_fc, \n",
    "                                                                     percent_match=percent_match,\n",
    "                                                                     remove_punc=remove_punc, lowercase=lowercase)\n",
    "        \n",
    "        if match_idx is None:\n",
    "            print(f\"\\nNO GT TEXT SEGMENT MATCH FOR BBOX, page_id: {pred_row.loc['page']} bbox_id: {pred_row.loc['bbId']}\")\n",
    "            \n",
    "            # assign False in case no match was found\n",
    "#             gt_file_contents.loc[match_idx, 'assigned_bbox'] = False\n",
    "#             gt_file_contents.loc[match_idx, 'assigned_page'] = False\n",
    "\n",
    "        else:\n",
    "            updated_bboxes.append(match_idx)\n",
    "\n",
    "            # assign the matched bbox coords to the gt segment\n",
    "            gt_file_contents.loc[match_idx, 'assigned_bbox'] = coords\n",
    "            gt_file_contents.loc[match_idx, 'assigned_page'] = page_num\n",
    "\n",
    "            # check if the match idx is indeed the min arg value of the col\n",
    "            assert match_idx == updated_gt_fc.loc[:, ['edit_distances']].sort_values(by=['edit_distances'], ascending=True).index[0], \\\n",
    "                    f\"INDEX OF MATCHED GT TEXT SEGMENT DOES NOT MATCH THE GT TEXT SEGMENT WITH LEAST EDIT DISTANCE!\\n\" + \\\n",
    "                    f\"doc_id: {doc_id}, pred_text: {pred_row['text']} match_idx: {match_idx}\\n\" + \\\n",
    "                    f\"Min Edit Distance: {unassigned_gt_fc['edit_distances'].min()} Match Threshold: {int(percent_match * len(pred_row['text']))}\\n\" + \\\n",
    "                    f\"Threshold Cond Check {unassigned_gt_fc['edit_distances'].min() < int(percent_match * len(pred_row['text']))}\\n\" + \\\n",
    "                    f\"\\n{updated_gt_fc}\"\n",
    "            \n",
    "\n",
    "            # verify if the update was performed successfully\n",
    "            assert gt_file_contents.loc[match_idx, 'assigned_bbox'] is not None, f\"GT FILE CONTENTS (BBOX) WAS NOT UPDATED SUCCESSFULLY! doc_id={doc_id}\"\n",
    "            assert gt_file_contents.loc[match_idx, 'assigned_page'] is not None, f\"GT FILE CONTENTS (PAGE) WAS NOT UPDATED SUCCESSFULLY! doc_id={doc_id}\"\n",
    "\n",
    "        \n",
    "        if debug:\n",
    "            print('\\n')\n",
    "            print(\"*\"* 25)\n",
    "            if match_idx is not None:\n",
    "                print(f\"SUCCESSFULL MATCH\\ndoc_id: {doc_id} page_id: {pred_row.loc['page']} bbox_id: {pred_row.loc['bbId']}\\n\")\n",
    "                print(f'match_idx: {match_idx}')\n",
    "                print(f\"pred_text: {pred_row.loc['text']}\\n\\nLength of Pred Text: {len(pred_row.loc['text'])}\")\n",
    "            else:\n",
    "                print(f\"\\nNO GT TEXT SEGMENT MATCH FOR BBOX, page_id: {pred_row.loc['page']} bbox_id: {pred_row.loc['bbId']}\")                \n",
    "                print(\n",
    "                      f\"doc_id: {doc_id}\\npred_text: {pred_row['text']}\\n\\nLength of Pred Text: {len(pred_row.loc['text'])} match_idx: {match_idx}\\n\" + \\\n",
    "                      f\"Min Edit Distance: {unassigned_gt_fc['edit_distances'].min()} Match Threshold: {int(percent_match * len(pred_row['text']))}\\n\" + \\\n",
    "                      f\"Threshold Cond Check {unassigned_gt_fc['edit_distances'].min() < int(percent_match * len(pred_row['text']))}\\n\"\n",
    "                        )\n",
    "                            \n",
    "            print(\"Candidate GT Segments With Edit Distances\")\n",
    "            display(updated_gt_fc)\n",
    "                    \n",
    "\n",
    "    # return the fully updated gt contents\n",
    "    return gt_file_contents, updated_bboxes\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130f81e0-1f70-41d8-b5ff-d0e30cd3db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(merged_df, window_size=2, debug=False, percent_match=0.5, remove_punc=True, lowercase=True):\n",
    "    '''Defines Execution Flow for a Set of Documents\n",
    "    \n",
    "    :param merged_df: pd.DataFrame. Consists of model preds (bboxes + text)\n",
    "        merged with gt text segments at a document level\n",
    "    '''\n",
    "    \n",
    "    print(f\"RUNNING ON {len(merged_df)} docs!\\nUser Args:\\n\\tWindow Size: {window_size}\\n\\tPercent Match: {percent_match}\\n\\tRemove Punc: {remove_punc}\\n\\tLowercase: {lowercase}\\n\\tdebug mode: {debug}\\n\")\n",
    "        \n",
    "    for idx, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc='Dataset Progbar'):        \n",
    "        doc_id = row.loc['doc_id']\n",
    "        if debug:\n",
    "            print(f\"doc_id: {doc_id}\")\n",
    "            \n",
    "        gt_file_contents = row.loc['file_contents_gt']\n",
    "\n",
    "        # create new col in the original file_contents_pred in the merged df to track if the bbox has been assigned to a gt segment\n",
    "        pred_file_contents = row.loc['file_contents_pred']\n",
    "        pred_file_contents['is_gt_assigned'] = False\n",
    "\n",
    "        pred_file_contents['text'] = pred_file_contents['text'].str.strip()\n",
    "                            \n",
    "        merged_df.loc[idx, \"file_contents_pred\"].update(pred_file_contents)\n",
    "        \n",
    "        # fetch the updated gt_file_contents, with bbox after matching\n",
    "        gt_file_contents, updated_bboxes = process_doc(doc_id, pred_file_contents, gt_file_contents, \n",
    "                                                       window_size=window_size, debug=debug,\n",
    "                                                       percent_match=percent_match,\n",
    "                                                       remove_punc=remove_punc, lowercase=lowercase)\n",
    "        \n",
    "        # update the merged_df with the updated gt_file_contents\n",
    "        merged_df.loc[idx, 'file_contents_gt'].update(gt_file_contents)\n",
    "        \n",
    "        # update the pred_file_contents with the bboxes that have been assigned\n",
    "        pred_file_contents.loc[updated_bboxes, 'is_gt_assigned'] = True\n",
    "        \n",
    "        # updated the merged_df with the updated pred_file_contents\n",
    "        merged_df.loc[idx, 'file_contents_pred'].update(pred_file_contents)\n",
    "\n",
    "        # verify that the merged_df was updated successfully\n",
    "        assert merged_df.loc[idx, 'file_contents_gt'].equals(gt_file_contents), f\"GT FILE CONTENTS WAS NOT UPDATED SUCCESSFULLY! doc_id={doc_id}\"\n",
    "        assert merged_df.loc[idx, 'file_contents_pred'].equals(pred_file_contents), f\"PRED FILE CONTENTS WAS NOT UPDATED SUCCESSFULLY! doc_id={doc_id}\"\n",
    "\n",
    "        # check if number of bboxes updated matches in the saved output\n",
    "        assert len(updated_bboxes) == len(pred_file_contents.loc[pred_file_contents['is_gt_assigned']]), f\"NUMBER OF UPDATED BBOXES DOESN'T MATCH OUTPUT! doc_id={doc_id}\"\n",
    "\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\n\\nNumber of bboxes in pred: {len(pred_file_contents)}\\nNumber of Assigned Pred Bboxes: {len(updated_bboxes)}\")\n",
    "            print(f\"Number of gt segments: {len(gt_file_contents)}\\nNumber of Assigned Gt Segments: {gt_file_contents['assigned_bbox'].notnull().sum()}\")  \n",
    "            \n",
    "            print(\"\\n\\nupdated gt_file_contents\")\n",
    "            display(gt_file_contents)\n",
    "            \n",
    "            print(\"\\n\\nupdated pred_file_contents\")\n",
    "            display(pred_file_contents)\n",
    "            print(\"*\" * 25)\n",
    "            \n",
    "            break\n",
    "\n",
    "        \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0fc9a-771e-4467-9ccb-8db9d2b2051a",
   "metadata": {},
   "source": [
    "# Define User Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031e502-989e-4ab7-965c-f19efec09de9",
   "metadata": {},
   "source": [
    "### Define data params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e076092-a48b-47e8-b3d5-37974a938096",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_txt_data_dir = \"../../CUAD_v1/full_contract_txt/\"\n",
    "gt_pdf_data_dir = \"../../CUAD_v1/full_contract_pdf/\"\n",
    "\n",
    "pred_data_dir = \"../../20220925_doctr_initial_csvs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd942c0-9eee-499c-a1f4-4cac2eb00d32",
   "metadata": {},
   "source": [
    "### Define Algo Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ef880-c0ef-4c77-a259-1b6aaa798ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 10 # number of gt_text segments to look at when performing matching\n",
    "debug = True # if the algo should be run in debug mode. Prints intermediate outputs at each step\n",
    "percent_match = 0.5 # if the edit distance of a predicted text segment is greater than this percent of the length of the segment, then ignore assigning that box to a gt\n",
    "remove_punc = True  # remove spaces, special chars and punctuation from string when computing edit distance\n",
    "lowercase = True # convert to lowercase when computing edit distance\n",
    "\n",
    "\n",
    "pdf_exts = ['.pdf', '.PDF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a511d-9c7c-48be-8672-7dc42e1a3bd6",
   "metadata": {},
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8de9774-d0cd-4804-9818-24956085ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the ground truth docs and parse into required structure\n",
    "gt_txt_filepaths = [fpath.resolve() for fpath in Path(gt_txt_data_dir).rglob(\"*.txt\")]\n",
    "\n",
    "gt_pdf_filepaths = []\n",
    "for ext in pdf_exts:\n",
    "    gt_pdf_filepaths += [fpath.resolve() for fpath in Path(gt_pdf_data_dir).rglob(f\"*{ext}\")]\n",
    "\n",
    "assert len(gt_txt_filepaths) == len(gt_pdf_filepaths), \"NUMBER OF GT TXT FILES DOES NOT MATCH NUMBER OF GT PDF FILES\"\n",
    "\n",
    "gt_txt_filepaths.sort()\n",
    "gt_pdf_filepaths.sort()\n",
    "\n",
    "gt_df = pd.DataFrame({\n",
    "                        'txt_filepath': gt_txt_filepaths,\n",
    "                        'pdf_filepath': gt_pdf_filepaths,\n",
    "                     })\n",
    "\n",
    "# create doc_id col\n",
    "gt_df['doc_id'] = gt_df['txt_filepath'].apply(lambda filepath: os.path.basename(filepath).rsplit('.', 1)[0])\n",
    "\n",
    "# # create col containing DF of all gt text segments\n",
    "gt_df['file_contents'] = gt_df['txt_filepath'].apply(lambda fname: read_gt_file(fname))\n",
    "\n",
    "print(f\"Length of GT DF: {len(gt_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7104c8d-9a39-44ff-8b58-285c2baf706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pred_df\n",
    "pred_df = pd.DataFrame({'filepath': [fpath.resolve() for fpath in Path(pred_data_dir).rglob(\"*.csv\")]})\n",
    "\n",
    "# create doc_id col\n",
    "pred_df['doc_id'] = pred_df['filepath'].apply(lambda filepath: os.path.basename(filepath).rsplit('.', 1)[0])\n",
    "\n",
    "# create col containing DF of all pred text segments\n",
    "pred_df['file_contents'] = pred_df['filepath'].apply(lambda fname: pd.read_csv(fname, index_col=0))\n",
    "\n",
    "print(f\"Length of PRED DF: {len(pred_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb316c-5efe-4898-9381-991a1c24837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform inner join b/w pred and gt text segments on doc_id\n",
    "merged_df = pred_df.merge(gt_df, how='inner', left_on='doc_id', right_on='doc_id', suffixes=['_pred', '_gt'])\n",
    "\n",
    "# merged_df = merged_df.sample(frac=1.0)\n",
    "print(f\"Length of MERGED DF: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae9a7b4-6fb5-43e0-bd7a-0883973d7fee",
   "metadata": {},
   "source": [
    "### Display sample of each df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f98ce-b3ef-40e7-9524-823493437093",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b1454c-9285-44dc-9bb2-f2396962dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1621fb6e-3c00-400e-a4f3-91d282323e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4e7bd-2383-4c27-962f-9e885468fe48",
   "metadata": {},
   "source": [
    "## Run Process on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84098ec-e4d7-408d-8ee8-f633e8646ceb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df = process_dataset(merged_df, window_size=window_size, debug=debug, percent_match=percent_match, remove_punc=remove_punc, lowercase=lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6ecde8-b38b-4325-8394-34db23da5500",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e2f30-19fc-44b8-bfcf-8c4624b4cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample random doc or let user choose\n",
    "# take gt results for the doc and draw bboxes on the pdf doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48efea-aedb-450b-93d0-2c559d8165d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'from this Exhibit 10.8 \\nfiled with the Securi...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa128fc-b105-4e5c-8199-f2b180560e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlation_table = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff231846-5d22-464d-919d-129120a8333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.translate(xlation_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1cd9d-6d18-4003-af09-8e804891b538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363a43c-dc33-44b4-b9dd-b43eaff6f5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47200047-a988-4755-8993-e44729ddbde3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_py3",
   "language": "python",
   "name": "conda_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
